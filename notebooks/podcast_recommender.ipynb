{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yamini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yamini/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre-Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "podcasts_df = pd.read_pickle('../data/pickle_files/english_podcasts_detailed_cleaned.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "podcasts_df['text'] = podcasts_df[['title', 'producer', 'genre', 'description', 'episode_titles', 'episode_descriptions']].apply(lambda x: ' '.join(x), axis=1)\n",
    "podcasts_df = podcasts_df.drop(columns=['genre', 'description', 'num_episodes', 'rating', 'num_reviews', 'link', 'episode_titles', 'episode_descriptions'])\n",
    "podcasts_df['ID'] = list(range(podcasts_df.shape[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# utils\n",
    "stop = get_stop_words('en')\n",
    "stop = [re.sub(r'([^\\s\\w]|_)+', '', x) for x in stop]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def remove_stop(text, stop):\n",
    "    return [word for word in text if word not in stop ]\n",
    "\n",
    "def lemmatize(text, l_stemmer):\n",
    "    return [l_stemmer.lemmatize(word) for word in text]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def preprocess_text(text):\n",
    "    # remove mixed alphanumeric\n",
    "    text = re.sub(r\"\"\"(?x) \\b(?=\\w*\\d)\\w+\\s*\"\"\",\"\", text)\n",
    "    re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    text = remove_stop(text, stop)\n",
    "    text = lemmatize(text, WordNetLemmatizer())\n",
    "    \n",
    "    new_text = ' '.join(text)\n",
    "    return new_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "podcasts_df['text'] = podcasts_df['text'].map(preprocess_text)\n",
    "podcasts_df = podcasts_df.query('podcasts_df.text !=\"\"')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "podcasts_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>producer</th>\n",
       "      <th>text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History Hyenas with Chris Distefano and Yannis...</td>\n",
       "      <td>RiotCast Network</td>\n",
       "      <td>[history, hyena, chris, distefano, yannis, pap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curiosity Daily</td>\n",
       "      <td>Westwood One</td>\n",
       "      <td>[curiosity, daily, westwood, one, education, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spirits</td>\n",
       "      <td>Multitude</td>\n",
       "      <td>[spirit, multitude, history, boozy, mythology,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Soundtrack Show</td>\n",
       "      <td>iHeartRadio</td>\n",
       "      <td>[soundtrack, show, iheartradio, tv, film, soun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Writing Excuses</td>\n",
       "      <td>Brandon Sanderson, Mary Robinette Kowal, Dan W...</td>\n",
       "      <td>[writing, excuse, brandon, sanderson, mary, ko...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  History Hyenas with Chris Distefano and Yannis...   \n",
       "1                                    Curiosity Daily   \n",
       "2                                            Spirits   \n",
       "3                                The Soundtrack Show   \n",
       "4                                    Writing Excuses   \n",
       "\n",
       "                                            producer  \\\n",
       "0                                   RiotCast Network   \n",
       "1                                       Westwood One   \n",
       "2                                          Multitude   \n",
       "3                                        iHeartRadio   \n",
       "4  Brandon Sanderson, Mary Robinette Kowal, Dan W...   \n",
       "\n",
       "                                                text  ID  \n",
       "0  [history, hyena, chris, distefano, yannis, pap...   0  \n",
       "1  [curiosity, daily, westwood, one, education, a...   1  \n",
       "2  [spirit, multitude, history, boozy, mythology,...   2  \n",
       "3  [soundtrack, show, iheartradio, tv, film, soun...   3  \n",
       "4  [writing, excuse, brandon, sanderson, mary, ko...   4  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Podcast Recommender utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# helper functions\n",
    "def get_title_from_index(index):\n",
    "    return podcasts_df[podcasts_df.ID == index][\"title\"].values[0]\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    return podcasts_df[podcasts_df.title == title][\"ID\"].values[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def recommend(podcast_title, sim_matrix, number_recs=5):\n",
    "    podcast_id = get_index_from_title(podcast_title)\n",
    "    similar_podcasts =  list(enumerate(sim_matrix[podcast_id]))\n",
    "    sorted_similar_podcast = sorted(similar_podcasts,key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    recommendations = [get_title_from_index(sorted_similar_podcast[i][0]) for i in range(number_recs+2)]\n",
    "    return recommendations[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Podcasts we'll use to validate results\n",
    "sample_podcasts = ['The Daily', \"Murder, etc.\",'This American Life', 'Call Her Daddy', 'The Joe Rogan Experience']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bag of Words + Cosine Similarity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(podcasts_df[\"text\"])\n",
    "cv_cosine_sim = cosine_similarity(cv_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "for i in sample_podcasts:\n",
    "    print(\"If you liked {}, try: \".format(i))\n",
    "    recs = recommend(i, cv_cosine_sim)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recommendations for The Daily: \n",
      "     Impeachment Inquiry: Updates from The Washington Post\n",
      "     Impeachment: A Daily Podcast\n",
      "     The Takeaway\n",
      "     Article II: Inside Impeachment\n",
      "     The Daily 202's Big Idea\n",
      "     The 11th Hour with Brian Williams\n",
      "Recommendations for Murder, etc.: \n",
      "     Criminology\n",
      "     Murderville\n",
      "     Unsolved Murders: True Crime Stories\n",
      "     Murder Minute\n",
      "     Don't Talk to Strangers\n",
      "     True Crime All The Time Unsolved\n",
      "Recommendations for This American Life: \n",
      "     The Stoop Storytelling Series\n",
      "     The Story Home Children's Audio Stories\n",
      "     Spooky Boo's Scary Story Time\n",
      "     The Story Behind\n",
      "     This is the Gospel Podcast\n",
      "     1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "Recommendations for Call Her Daddy: \n",
      "     Stiff Socks\n",
      "     Two Judgey Girls\n",
      "     NAKED with Catt Sadler\n",
      "     Slay Girl Slay\n",
      "     Hot Marriage. Cool Parents.\n",
      "     Safe For Work\n",
      "Recommendations for The Joe Rogan Experience: \n",
      "     The Creative Penn Podcast For Writers\n",
      "     1001 Classic Short Stories & Tales\n",
      "     3 Books With Neil Pasricha\n",
      "     The Ground Up Show\n",
      "     1001 Stories For The Road\n",
      "     1001 Heroes, Legends, Histories & Mysteries Podcast\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFIDF + Cosine Similarity "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "tf = TfidfVectorizer()\n",
    "tf_matrix = tf.fit_transform(podcasts_df[\"text\"])\n",
    "tf_cosine_sim = cosine_similarity(tf_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "for i in sample_podcasts:\n",
    "    print(\"If you liked {}, try: \".format(i))\n",
    "    recs = recommend(i, tf_cosine_sim)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recommendations for The Daily: \n",
      "     Impeachment Inquiry: Updates from The Washington Post\n",
      "     The 11th Hour with Brian Williams\n",
      "     The Daily 202's Big Idea\n",
      "     Article II: Inside Impeachment\n",
      "     Impeachment: A Daily Podcast\n",
      "     The Takeaway\n",
      "Recommendations for Murder, etc.: \n",
      "     Murder Minute\n",
      "     Criminology\n",
      "     Murderville\n",
      "     Unsolved Murders: True Crime Stories\n",
      "     Don't Talk to Strangers\n",
      "     True Crime All The Time Unsolved\n",
      "Recommendations for This American Life: \n",
      "     Experimental Brewing\n",
      "     1A\n",
      "     Through the Looking Glass: A LOST Retrospective\n",
      "     The Grave Talks | Haunted, Paranormal & Supernatural\n",
      "     Darkness Prevails Podcast | TRUE Horror Stories\n",
      "     BeerSmith Home and Beer Brewing Podcast\n",
      "Recommendations for Call Her Daddy: \n",
      "     hey, girl.\n",
      "     Girls Night with Stephanie May Wilson\n",
      "     Stiff Socks\n",
      "     Fierce Girls\n",
      "     Becoming Something with Jonathan Pokluda\n",
      "     Two Judgey Girls\n",
      "Recommendations for The Joe Rogan Experience: \n",
      "     MILLION DOLLAR LIFE LESSONS\n",
      "     Malcolm Gladwell, Revisionist History: Special Event\n",
      "     The Horror of Dolores Roach\n",
      "     Jordan Peterson Interviews & Speeches\n",
      "     Revisionist History\n",
      "     Ari Shaffir's Skeptic Tank\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare results of the two models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def compare(pod, num_recs=5):\n",
    "    tf_idf_recs = recommend(pod, tf_cosine_sim, num_recs)\n",
    "    cv_recs = recommend(pod, cv_cosine_sim, num_recs)\n",
    "\n",
    "    both = list(set(tf_idf_recs).intersection(set(cv_recs)))\n",
    "    unique_to_tf = list(set(tf_idf_recs).difference(set(cv_recs)))\n",
    "    unique_to_cv = list(set(cv_recs).difference(set(tf_idf_recs)))\n",
    "    print(\"Recs for {}: \".format(pod))\n",
    "    \n",
    "    print(\"    Recommended by both tf-idf and cv:\")\n",
    "    for i in both: print(\"         {}\".format(i))\n",
    "\n",
    "    print(\"    Uniqely recommended by tf-idf:\")\n",
    "    for i in unique_to_tf: print(\"         {}\".format(i))\n",
    "\n",
    "    print(\"    Uniqely recommended by cv:\")\n",
    "    for i in unique_to_cv: print(\"         {}\".format(i))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "for pod in sample_podcasts: compare(pod) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recs for The Daily: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         The Daily 202's Big Idea\n",
      "         Impeachment Inquiry: Updates from The Washington Post\n",
      "         The 11th Hour with Brian Williams\n",
      "         The Takeaway\n",
      "         Article II: Inside Impeachment\n",
      "         Impeachment: A Daily Podcast\n",
      "    Uniqely recommended by tf-idf:\n",
      "    Uniqely recommended by cv:\n",
      "Recs for Murder, etc.: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         Criminology\n",
      "         Unsolved Murders: True Crime Stories\n",
      "         Don't Talk to Strangers\n",
      "         Murderville\n",
      "         Murder Minute\n",
      "         True Crime All The Time Unsolved\n",
      "    Uniqely recommended by tf-idf:\n",
      "    Uniqely recommended by cv:\n",
      "Recs for This American Life: \n",
      "    Recommended by both tf-idf and cv:\n",
      "    Uniqely recommended by tf-idf:\n",
      "         1A\n",
      "         Experimental Brewing\n",
      "         BeerSmith Home and Beer Brewing Podcast\n",
      "         The Grave Talks | Haunted, Paranormal & Supernatural\n",
      "         Darkness Prevails Podcast | TRUE Horror Stories\n",
      "         Through the Looking Glass: A LOST Retrospective\n",
      "    Uniqely recommended by cv:\n",
      "         This is the Gospel Podcast\n",
      "         The Story Behind\n",
      "         The Stoop Storytelling Series\n",
      "         The Story Home Children's Audio Stories\n",
      "         1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "         Spooky Boo's Scary Story Time\n",
      "Recs for Call Her Daddy: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         Stiff Socks\n",
      "         Two Judgey Girls\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Fierce Girls\n",
      "         Becoming Something with Jonathan Pokluda\n",
      "         Girls Night with Stephanie May Wilson\n",
      "         hey, girl.\n",
      "    Uniqely recommended by cv:\n",
      "         Slay Girl Slay\n",
      "         Safe For Work\n",
      "         Hot Marriage. Cool Parents.\n",
      "         NAKED with Catt Sadler\n",
      "Recs for The Joe Rogan Experience: \n",
      "    Recommended by both tf-idf and cv:\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Jordan Peterson Interviews & Speeches\n",
      "         Revisionist History\n",
      "         Ari Shaffir's Skeptic Tank\n",
      "         MILLION DOLLAR LIFE LESSONS\n",
      "         The Horror of Dolores Roach\n",
      "         Malcolm Gladwell, Revisionist History: Special Event\n",
      "    Uniqely recommended by cv:\n",
      "         3 Books With Neil Pasricha\n",
      "         The Creative Penn Podcast For Writers\n",
      "         1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "         The Ground Up Show\n",
      "         1001 Classic Short Stories & Tales\n",
      "         1001 Stories For The Road\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}