{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import itertools\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yamini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/yamini/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre-Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "podcasts_df = pd.read_pickle('../data/data/pickle_files/english_podcasts_detailed_cleaned.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "podcasts_df['text'] = podcasts_df[['title', 'producer', 'genre', 'description', 'episode_titles', 'episode_descriptions']].apply(lambda x: ' '.join(x), axis=1)\n",
    "podcasts_df = podcasts_df.drop(columns=['genre', 'description', 'num_episodes', 'rating', 'num_reviews', 'link', 'episode_titles', 'episode_descriptions'])\n",
    "podcasts_df['ID'] = list(range(podcasts_df.shape[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# utils\n",
    "stop = get_stop_words('en')\n",
    "stop = [re.sub(r'([^\\s\\w]|_)+', '', x) for x in stop]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def remove_stop(text, stop):\n",
    "    return [word for word in text if word not in stop ]\n",
    "\n",
    "def lemmatize(text, l_stemmer):\n",
    "    return [l_stemmer.lemmatize(word) for word in text]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def preprocess_text(text):\n",
    "    # remove mixed alphanumeric\n",
    "    text = re.sub(r\"\"\"(?x) \\b(?=\\w*\\d)\\w+\\s*\"\"\",\"\", text)\n",
    "    re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    text = remove_stop(text, stop)\n",
    "    text = lemmatize(text, WordNetLemmatizer())\n",
    "    \n",
    "    new_text = ' '.join(text)\n",
    "    return new_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "podcasts_df['text'] = podcasts_df['text'].map(preprocess_text)\n",
    "podcasts_df = podcasts_df.query('text !=\"\"')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Podcast Recommender utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# helper functions\n",
    "def get_title_from_index(index):\n",
    "    return podcasts_df[podcasts_df.ID == index][\"title\"].values[0]\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    return podcasts_df[podcasts_df.title == title][\"ID\"].values[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def recommend(podcast_title, sim_matrix, number_recs=5):\n",
    "    podcast_id = get_index_from_title(podcast_title)\n",
    "    similar_podcasts =  list(enumerate(sim_matrix[podcast_id]))\n",
    "    sorted_similar_podcast = sorted(similar_podcasts,key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    recommendations = [get_title_from_index(sorted_similar_podcast[i][0]) for i in range(number_recs+2)]\n",
    "    return recommendations[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Podcasts we'll use to validate results\n",
    "sample_podcasts = ['The Daily', \"Murder, etc.\",'This American Life', 'Call Her Daddy', 'The Joe Rogan Experience']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bag of Words + Cosine Similarity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(podcasts_df[\"text\"])\n",
    "cv_cosine_sim = cosine_similarity(cv_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "for i in sample_podcasts:\n",
    "    print(\"If you liked {}, try: \".format(i))\n",
    "    recs = recommend(i, cv_cosine_sim)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "If you liked The Daily, try: \n",
      "     Impeachment Inquiry: Updates from The Washington Post\n",
      "     Impeachment: A Daily Podcast\n",
      "     The Takeaway\n",
      "     Article II: Inside Impeachment\n",
      "     The Daily 202's Big Idea\n",
      "     The 11th Hour with Brian Williams\n",
      "If you liked Murder, etc., try: \n",
      "     Criminology\n",
      "     Murderville\n",
      "     Unsolved Murders: True Crime Stories\n",
      "     Murder Minute\n",
      "     Don't Talk to Strangers\n",
      "     True Crime All The Time Unsolved\n",
      "If you liked This American Life, try: \n",
      "     The Stoop Storytelling Series\n",
      "     The Story Home Children's Audio Stories\n",
      "     Spooky Boo's Scary Story Time\n",
      "     The Story Behind\n",
      "     This is the Gospel Podcast\n",
      "     1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "If you liked Call Her Daddy, try: \n",
      "     Stiff Socks\n",
      "     Two Judgey Girls\n",
      "     NAKED with Catt Sadler\n",
      "     Slay Girl Slay\n",
      "     Hot Marriage. Cool Parents.\n",
      "     Safe For Work\n",
      "If you liked The Joe Rogan Experience, try: \n",
      "     The Creative Penn Podcast For Writers\n",
      "     1001 Classic Short Stories & Tales\n",
      "     3 Books With Neil Pasricha\n",
      "     The Ground Up Show\n",
      "     1001 Stories For The Road\n",
      "     1001 Heroes, Legends, Histories & Mysteries Podcast\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFIDF + Cosine Similarity "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "tf = TfidfVectorizer()\n",
    "tf_matrix = tf.fit_transform(podcasts_df[\"text\"])\n",
    "tf_cosine_sim = cosine_similarity(tf_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for i in sample_podcasts:\n",
    "    print(\"If you liked {}, try: \".format(i))\n",
    "    recs = recommend(i, tf_cosine_sim)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "If you liked The Daily, try: \n",
      "     Impeachment Inquiry: Updates from The Washington Post\n",
      "     The 11th Hour with Brian Williams\n",
      "     The Daily 202's Big Idea\n",
      "     Article II: Inside Impeachment\n",
      "     Impeachment: A Daily Podcast\n",
      "     The Takeaway\n",
      "If you liked Murder, etc., try: \n",
      "     Murder Minute\n",
      "     Criminology\n",
      "     Murderville\n",
      "     Unsolved Murders: True Crime Stories\n",
      "     Don't Talk to Strangers\n",
      "     True Crime All The Time Unsolved\n",
      "If you liked This American Life, try: \n",
      "     Experimental Brewing\n",
      "     1A\n",
      "     Through the Looking Glass: A LOST Retrospective\n",
      "     The Grave Talks | Haunted, Paranormal & Supernatural\n",
      "     Darkness Prevails Podcast | TRUE Horror Stories\n",
      "     BeerSmith Home and Beer Brewing Podcast\n",
      "If you liked Call Her Daddy, try: \n",
      "     hey, girl.\n",
      "     Girls Night with Stephanie May Wilson\n",
      "     Stiff Socks\n",
      "     Fierce Girls\n",
      "     Becoming Something with Jonathan Pokluda\n",
      "     Two Judgey Girls\n",
      "If you liked The Joe Rogan Experience, try: \n",
      "     MILLION DOLLAR LIFE LESSONS\n",
      "     Malcolm Gladwell, Revisionist History: Special Event\n",
      "     The Horror of Dolores Roach\n",
      "     Jordan Peterson Interviews & Speeches\n",
      "     Revisionist History\n",
      "     Ari Shaffir's Skeptic Tank\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare results of the two models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def print_compare(pod, num_recs=5):\n",
    "    \"\"\"for a given podcast and number of recommendations\n",
    "        print the recommendations from both tf-idf and cv\n",
    "        unique to tf-idf\n",
    "        and unique to cv\n",
    "    \"\"\"\n",
    "\n",
    "    tf_idf_recs = recommend(pod, tf_cosine_sim, num_recs)\n",
    "    cv_recs = recommend(pod, cv_cosine_sim, num_recs)\n",
    "\n",
    "    both = list(set(tf_idf_recs).intersection(set(cv_recs)))\n",
    "    unique_to_tf = list(set(tf_idf_recs).difference(set(cv_recs)))\n",
    "    unique_to_cv = list(set(cv_recs).difference(set(tf_idf_recs)))\n",
    "    print(\"Recs for {}: \".format(pod))\n",
    "    \n",
    "    print(\"    Recommended by both tf-idf and cv:\")\n",
    "    for i in both: print(\"         {}\".format(i))\n",
    "\n",
    "    print(\"    Uniqely recommended by tf-idf:\")\n",
    "    for i in unique_to_tf: print(\"         {}\".format(i))\n",
    "\n",
    "    print(\"    Uniqely recommended by cv:\")\n",
    "    for i in unique_to_cv: print(\"         {}\".format(i))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for pod in sample_podcasts: print_compare(pod) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recs for The Daily: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         The Takeaway\n",
      "         Impeachment: A Daily Podcast\n",
      "         The 11th Hour with Brian Williams\n",
      "         Article II: Inside Impeachment\n",
      "         Impeachment Inquiry: Updates from The Washington Post\n",
      "         The Daily 202's Big Idea\n",
      "    Uniqely recommended by tf-idf:\n",
      "    Uniqely recommended by cv:\n",
      "Recs for Murder, etc.: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         Criminology\n",
      "         Unsolved Murders: True Crime Stories\n",
      "         Murder Minute\n",
      "         Don't Talk to Strangers\n",
      "         True Crime All The Time Unsolved\n",
      "         Murderville\n",
      "    Uniqely recommended by tf-idf:\n",
      "    Uniqely recommended by cv:\n",
      "Recs for This American Life: \n",
      "    Recommended by both tf-idf and cv:\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Darkness Prevails Podcast | TRUE Horror Stories\n",
      "         The Grave Talks | Haunted, Paranormal & Supernatural\n",
      "         Through the Looking Glass: A LOST Retrospective\n",
      "         1A\n",
      "         Experimental Brewing\n",
      "         BeerSmith Home and Beer Brewing Podcast\n",
      "    Uniqely recommended by cv:\n",
      "         The Story Home Children's Audio Stories\n",
      "         Spooky Boo's Scary Story Time\n",
      "         1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "         This is the Gospel Podcast\n",
      "         The Story Behind\n",
      "         The Stoop Storytelling Series\n",
      "Recs for Call Her Daddy: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         Two Judgey Girls\n",
      "         Stiff Socks\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Girls Night with Stephanie May Wilson\n",
      "         Becoming Something with Jonathan Pokluda\n",
      "         hey, girl.\n",
      "         Fierce Girls\n",
      "    Uniqely recommended by cv:\n",
      "         Safe For Work\n",
      "         Hot Marriage. Cool Parents.\n",
      "         NAKED with Catt Sadler\n",
      "         Slay Girl Slay\n",
      "Recs for The Joe Rogan Experience: \n",
      "    Recommended by both tf-idf and cv:\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Ari Shaffir's Skeptic Tank\n",
      "         Revisionist History\n",
      "         The Horror of Dolores Roach\n",
      "         Malcolm Gladwell, Revisionist History: Special Event\n",
      "         MILLION DOLLAR LIFE LESSONS\n",
      "         Jordan Peterson Interviews & Speeches\n",
      "    Uniqely recommended by cv:\n",
      "         3 Books With Neil Pasricha\n",
      "         1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "         1001 Classic Short Stories & Tales\n",
      "         The Ground Up Show\n",
      "         1001 Stories For The Road\n",
      "         The Creative Penn Podcast For Writers\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "def coverage(model_name, sim_matrix, num_recs=10):\n",
    "    \"\"\"keep track of the top n recommendations for each podcast\n",
    "    \"\"\"\n",
    "    indices = np.argpartition(sim_matrix, -num_recs, axis=1)[:,-num_recs:]\n",
    "    \n",
    "    #calculating coverage:\n",
    "    recommended = set(list(itertools.chain(*indices)))\n",
    "    coverage = (len(recommended)/indices.shape[0])*100\n",
    "\n",
    "    print(\"Stats for {} Model with {} recs\".format(model_name, num_recs))\n",
    "    print(\"    Coverage: {} %\".format(coverage))\n",
    "    \n",
    "    return indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "cv_recs_10 = coverage(\"CountVectorizer\", cv_cosine_sim, 5)\n",
    "tf_idf_recs_10 = coverage(\"tf-idf\", tf_cosine_sim, 5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stats for CountVectorizer Model with 5 recs\n",
      "    Coverage: 100.0 %\n",
      "Stats for tf-idf Model with 5 recs\n",
      "    Coverage: 100.0 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}