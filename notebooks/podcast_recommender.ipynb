{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import itertools\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yamini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre-Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "podcasts_df_orig = pd.read_pickle('../data/data/pickle_files/english_podcasts_detailed_cleaned.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "podcasts_df = podcasts_df_orig\n",
    "podcasts_df['text'] = podcasts_df[['title', 'producer', 'genre', 'description', 'episode_titles', 'episode_descriptions']].apply(lambda x: ' '.join(x), axis=1)\n",
    "podcasts_df = podcasts_df.drop(columns=['genre', 'description', 'num_episodes', 'rating', 'num_reviews', 'link', 'episode_titles', 'episode_descriptions'])\n",
    "podcasts_df['idx'] = list(range(podcasts_df.shape[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# utils\n",
    "stop = get_stop_words('en')\n",
    "stop = [re.sub(r'([^\\s\\w]|_)+', '', x) for x in stop]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def remove_stop(text, stop):\n",
    "    return [word for word in text if word not in stop ]\n",
    "\n",
    "def lemmatize(text, l_stemmer):\n",
    "    return [l_stemmer.lemmatize(word) for word in text]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def preprocess_text(text):\n",
    "    # remove mixed alphanumeric\n",
    "    text = re.sub(r\"\"\"(?x) \\b(?=\\w*\\d)\\w+\\s*\"\"\",\"\", text)\n",
    "    re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    text = remove_stop(text, stop)\n",
    "    text = lemmatize(text, WordNetLemmatizer())\n",
    "    \n",
    "    new_text = ' '.join(text)\n",
    "    return new_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "podcasts_df['text'] = podcasts_df['text'].map(preprocess_text)\n",
    "podcasts_df = podcasts_df.query('text !=\"\"')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Podcast-recommender utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# helper functions\n",
    "def get_title_from_index(index):\n",
    "    \"\"\"get title of podcast from index of podcast\n",
    "        parameters:\n",
    "            index: (int)\n",
    "        returns:\n",
    "            title (string)\n",
    "        raises:\n",
    "            ValueError: index not in podcasts_df\n",
    "    \"\"\"\n",
    "    return podcasts_df[podcasts_df.idx == index][\"title\"].values[0]\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    \"\"\"get index of podcast from title of podcast\n",
    "        parameters:\n",
    "            title: (string)\n",
    "        returns:\n",
    "            index (int)\n",
    "        raises:\n",
    "            ValueError: string not in podcasts_df['title]\n",
    "    \"\"\"\n",
    "    return podcasts_df[podcasts_df.title == title][\"idx\"].values[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def recommend(podcast_title, sim_matrix, number_recs=5):\n",
    "    \"\"\"given a podcast title & a similarity matrix, return n most similar podcasts\n",
    "        parameters:\n",
    "            podcast_title: (str) must be in podcasts_tf['title]\n",
    "            sim_matrix: (np.array) similarity matrix\n",
    "            number_recs: (int) how many recommendations do you want per title?\n",
    "        returns:\n",
    "            recommendations: (list[str]) list of n most similar podcasts \n",
    "                            according to the similarity matrix\n",
    "    \"\"\"\n",
    "\n",
    "    podcast_id = get_index_from_title(podcast_title)\n",
    "    similar_podcasts =  list(enumerate(sim_matrix[podcast_id]))\n",
    "    sorted_similar_podcast = sorted(similar_podcasts,key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    recommendations = [get_title_from_index(sorted_similar_podcast[i][0]) for i in range(number_recs+2)]\n",
    "    return recommendations[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def recommend_print(podcast_title, sim_matrix, number_recs=5):\n",
    "    print(\"If you liked {}, try: \".format(podcast_title))\n",
    "    recs = recommend(podcast_title, sim_matrix, number_recs)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Podcasts we'll use to validate results\n",
    "sample_podcasts = ['The Daily', \"Murder, etc.\",'This American Life', 'Call Her Daddy', 'The Joe Rogan Experience']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bag of Words + Cosine Similarity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(podcasts_df[\"text\"])\n",
    "cv_cosine_sim = cosine_similarity(cv_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "for i in sample_podcasts:\n",
    "    print(\"If you liked {}, try: \".format(i))\n",
    "    recs = recommend(i, cv_cosine_sim)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "If you liked The Daily, try: \n",
      "     Impeachment Inquiry: Updates from The Washington Post\n",
      "     Impeachment: A Daily Podcast\n",
      "     The Takeaway\n",
      "     Article II: Inside Impeachment\n",
      "     The Daily 202's Big Idea\n",
      "     The 11th Hour with Brian Williams\n",
      "If you liked Murder, etc., try: \n",
      "     Criminology\n",
      "     Murderville\n",
      "     Unsolved Murders: True Crime Stories\n",
      "     Murder Minute\n",
      "     Don't Talk to Strangers\n",
      "     True Crime All The Time Unsolved\n",
      "If you liked This American Life, try: \n",
      "     The Stoop Storytelling Series\n",
      "     The Story Home Children's Audio Stories\n",
      "     Spooky Boo's Scary Story Time\n",
      "     The Story Behind\n",
      "     This is the Gospel Podcast\n",
      "     1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "If you liked Call Her Daddy, try: \n",
      "     Stiff Socks\n",
      "     Two Judgey Girls\n",
      "     NAKED with Catt Sadler\n",
      "     Slay Girl Slay\n",
      "     Hot Marriage. Cool Parents.\n",
      "     Safe For Work\n",
      "If you liked The Joe Rogan Experience, try: \n",
      "     The Creative Penn Podcast For Writers\n",
      "     1001 Classic Short Stories & Tales\n",
      "     3 Books With Neil Pasricha\n",
      "     The Ground Up Show\n",
      "     1001 Stories For The Road\n",
      "     1001 Heroes, Legends, Histories & Mysteries Podcast\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TFIDF + Cosine Similarity "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "tf = TfidfVectorizer()\n",
    "tf_matrix = tf.fit_transform(podcasts_df[\"text\"])\n",
    "tf_cosine_sim = cosine_similarity(tf_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for i in sample_podcasts:\n",
    "    print(\"If you liked {}, try: \".format(i))\n",
    "    recs = recommend(i, tf_cosine_sim)\n",
    "    for i in recs:\n",
    "        print(\"     {}\".format(i))\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "If you liked The Daily, try: \n",
      "     Impeachment Inquiry: Updates from The Washington Post\n",
      "     The 11th Hour with Brian Williams\n",
      "     The Daily 202's Big Idea\n",
      "     Article II: Inside Impeachment\n",
      "     Impeachment: A Daily Podcast\n",
      "     The Takeaway\n",
      "If you liked Murder, etc., try: \n",
      "     Murder Minute\n",
      "     Criminology\n",
      "     Murderville\n",
      "     Unsolved Murders: True Crime Stories\n",
      "     Don't Talk to Strangers\n",
      "     True Crime All The Time Unsolved\n",
      "If you liked This American Life, try: \n",
      "     Experimental Brewing\n",
      "     1A\n",
      "     Through the Looking Glass: A LOST Retrospective\n",
      "     The Grave Talks | Haunted, Paranormal & Supernatural\n",
      "     Darkness Prevails Podcast | TRUE Horror Stories\n",
      "     BeerSmith Home and Beer Brewing Podcast\n",
      "If you liked Call Her Daddy, try: \n",
      "     hey, girl.\n",
      "     Girls Night with Stephanie May Wilson\n",
      "     Stiff Socks\n",
      "     Fierce Girls\n",
      "     Becoming Something with Jonathan Pokluda\n",
      "     Two Judgey Girls\n",
      "If you liked The Joe Rogan Experience, try: \n",
      "     MILLION DOLLAR LIFE LESSONS\n",
      "     Malcolm Gladwell, Revisionist History: Special Event\n",
      "     The Horror of Dolores Roach\n",
      "     Jordan Peterson Interviews & Speeches\n",
      "     Revisionist History\n",
      "     Ari Shaffir's Skeptic Tank\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare results of the two models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def print_compare(pod, num_recs=5):\n",
    "    \"\"\"for a given podcast and number of recommendations\n",
    "        print the recommendations from both tf-idf and cv\n",
    "        unique to tf-idf\n",
    "        and unique to cv\n",
    "    \"\"\"\n",
    "\n",
    "    tf_idf_recs = recommend(pod, tf_cosine_sim, num_recs)\n",
    "    cv_recs = recommend(pod, cv_cosine_sim, num_recs)\n",
    "\n",
    "    both = list(set(tf_idf_recs).intersection(set(cv_recs)))\n",
    "    unique_to_tf = list(set(tf_idf_recs).difference(set(cv_recs)))\n",
    "    unique_to_cv = list(set(cv_recs).difference(set(tf_idf_recs)))\n",
    "    print(\"Recs for {}: \".format(pod))\n",
    "    \n",
    "    print(\"    Recommended by both tf-idf and cv:\")\n",
    "    for i in both: print(\"         {}\".format(i))\n",
    "\n",
    "    print(\"    Uniqely recommended by tf-idf:\")\n",
    "    for i in unique_to_tf: print(\"         {}\".format(i))\n",
    "\n",
    "    print(\"    Uniqely recommended by cv:\")\n",
    "    for i in unique_to_cv: print(\"         {}\".format(i))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for pod in sample_podcasts: print_compare(pod) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recs for The Daily: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         The Takeaway\n",
      "         Impeachment: A Daily Podcast\n",
      "         The 11th Hour with Brian Williams\n",
      "         Article II: Inside Impeachment\n",
      "         Impeachment Inquiry: Updates from The Washington Post\n",
      "         The Daily 202's Big Idea\n",
      "    Uniqely recommended by tf-idf:\n",
      "    Uniqely recommended by cv:\n",
      "Recs for Murder, etc.: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         Criminology\n",
      "         Unsolved Murders: True Crime Stories\n",
      "         Murder Minute\n",
      "         Don't Talk to Strangers\n",
      "         True Crime All The Time Unsolved\n",
      "         Murderville\n",
      "    Uniqely recommended by tf-idf:\n",
      "    Uniqely recommended by cv:\n",
      "Recs for This American Life: \n",
      "    Recommended by both tf-idf and cv:\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Darkness Prevails Podcast | TRUE Horror Stories\n",
      "         The Grave Talks | Haunted, Paranormal & Supernatural\n",
      "         Through the Looking Glass: A LOST Retrospective\n",
      "         1A\n",
      "         Experimental Brewing\n",
      "         BeerSmith Home and Beer Brewing Podcast\n",
      "    Uniqely recommended by cv:\n",
      "         The Story Home Children's Audio Stories\n",
      "         Spooky Boo's Scary Story Time\n",
      "         1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "         This is the Gospel Podcast\n",
      "         The Story Behind\n",
      "         The Stoop Storytelling Series\n",
      "Recs for Call Her Daddy: \n",
      "    Recommended by both tf-idf and cv:\n",
      "         Two Judgey Girls\n",
      "         Stiff Socks\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Girls Night with Stephanie May Wilson\n",
      "         Becoming Something with Jonathan Pokluda\n",
      "         hey, girl.\n",
      "         Fierce Girls\n",
      "    Uniqely recommended by cv:\n",
      "         Safe For Work\n",
      "         Hot Marriage. Cool Parents.\n",
      "         NAKED with Catt Sadler\n",
      "         Slay Girl Slay\n",
      "Recs for The Joe Rogan Experience: \n",
      "    Recommended by both tf-idf and cv:\n",
      "    Uniqely recommended by tf-idf:\n",
      "         Ari Shaffir's Skeptic Tank\n",
      "         Revisionist History\n",
      "         The Horror of Dolores Roach\n",
      "         Malcolm Gladwell, Revisionist History: Special Event\n",
      "         MILLION DOLLAR LIFE LESSONS\n",
      "         Jordan Peterson Interviews & Speeches\n",
      "    Uniqely recommended by cv:\n",
      "         3 Books With Neil Pasricha\n",
      "         1001 Heroes, Legends, Histories & Mysteries Podcast\n",
      "         1001 Classic Short Stories & Tales\n",
      "         The Ground Up Show\n",
      "         1001 Stories For The Road\n",
      "         The Creative Penn Podcast For Writers\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "def coverage(model_name, sim_matrix, num_recs=10):\n",
    "    \"\"\"keep track of the top n recommendations for each podcast\n",
    "    \"\"\"\n",
    "    indices = np.argpartition(sim_matrix, -num_recs, axis=1)[:,-num_recs:]\n",
    "    \n",
    "    #calculating coverage:\n",
    "    recommended = set(list(itertools.chain(*indices)))\n",
    "    coverage = (len(recommended)/indices.shape[0])*100\n",
    "\n",
    "    print(\"Stats for {} Model with {} recs\".format(model_name, num_recs))\n",
    "    print(\"    Coverage: {} %\".format(coverage))\n",
    "    \n",
    "    return indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "cv_recs_10 = coverage(\"CountVectorizer\", cv_cosine_sim, 5)\n",
    "tf_idf_recs_10 = coverage(\"tf-idf\", tf_cosine_sim, 5)\n",
    "\n",
    "#Note: Are these accurate?"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stats for CountVectorizer Model with 5 recs\n",
      "    Coverage: 100.0 %\n",
      "Stats for tf-idf Model with 5 recs\n",
      "    Coverage: 100.0 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generating Fake User Ratings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# We want to create users that have preferences\n",
    "# Each of them randomly rates 5-20 random podcasts \n",
    "# This is a bad way to generate fake user ratings\n",
    "# but for now it'll do"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "users_count = 10000\n",
    "podcasts = np.arange(0, podcasts_df.shape[0]+1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "def generate_user_ratings(users_count):\n",
    "    user_ratings = []\n",
    "    for idx, user in enumerate(np.arange(0,users_count)):\n",
    "        ratings = []\n",
    "        quantity_rated = np.random.randint(5,21)\n",
    "        reviewed = set()\n",
    "        \n",
    "        for i in np.arange(quantity_rated):\n",
    "            podcast =  np.random.randint(0, podcasts_df.shape[0]+1)\n",
    "            \n",
    "            # don't want the same user to review the same podcast multiple times\n",
    "            while (podcast in reviewed):\n",
    "                podcast =  np.random.randint(0, podcasts_df.shape[0]+1)\n",
    "            reviewed.add(podcast)\n",
    "\n",
    "            rating = np.random.randint(0,6)\n",
    "            ratings.append([podcast, rating])\n",
    "        \n",
    "        user_df = pd.DataFrame(ratings, columns=['podcast_idx', 'rating'])\n",
    "        user_df['user_id'] = idx\n",
    "\n",
    "        user_ratings.append(user_df)\n",
    "\n",
    "    return pd.concat(user_ratings)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "usr = generate_user_ratings(1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "usr.pivot_table('podcast_idx', index='user_id', columns='rating', aggfunc='count', margins=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rating</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2092.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2054.0</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>12314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "rating        0       1       2       3       4       5    All\n",
       "user_id                                                       \n",
       "0           1.0     1.0     1.0     1.0     1.0     1.0      6\n",
       "1           1.0     2.0     2.0     1.0     2.0     NaN      8\n",
       "2           NaN     4.0     2.0     2.0     5.0     3.0     16\n",
       "3           3.0     1.0     2.0     6.0     3.0     2.0     17\n",
       "4           1.0     4.0     3.0     2.0     3.0     1.0     14\n",
       "...         ...     ...     ...     ...     ...     ...    ...\n",
       "996         4.0     2.0     6.0     5.0     2.0     1.0     20\n",
       "997         1.0     3.0     NaN     NaN     2.0     1.0      7\n",
       "998         1.0     1.0     1.0     NaN     2.0     1.0      6\n",
       "999         NaN     1.0     2.0     4.0     3.0     2.0     12\n",
       "All      2092.0  2109.0  1987.0  2054.0  2092.0  1980.0  12314\n",
       "\n",
       "[1001 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}